Remove ASM code when it is avoidable, to ease Frama-C analysis.

This modifies the generated/analyzed code as it means taking the "slow
fail-over untested path".

--- a/arch/x86/include/asm/cpufeature.h
+++ b/arch/x86/include/asm/cpufeature.h
@@ -373,7 +373,7 @@ extern const char * const x86_bug_flags[
 
 #endif /* CONFIG_X86_64 */
 
-#if __GNUC__ >= 4
+#if __GNUC__ >= 4 && !defined(__FRAMAC__)
 extern void warn_pre_alternatives(void);
 extern bool __static_cpu_has_safe(u16 bit);
 
--- a/arch/x86/include/asm/bitops.h
+++ b/arch/x86/include/asm/bitops.h
@@ -12,6 +12,13 @@
 #error only <linux/bitops.h> can be included directly
 #endif
 
+#ifdef __FRAMAC__
+/* Use C definitions for Frama-C */
+#include <linux/types.h> /* for bool */
+#include <asm-generic/bitops.h>
+
+#else /* __FRAMAC__ */
+
 #include <linux/compiler.h>
 #include <asm/alternative.h>
 #include <asm/rmwcc.h>
@@ -505,5 +512,7 @@ static __always_inline int fls64(__u64 x
 
 #include <asm-generic/bitops/ext2-atomic-setbit.h>
 
+#endif /* __FRAMAC__ */
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_X86_BITOPS_H */
--- a/arch/x86/include/asm/atomic.h
+++ b/arch/x86/include/asm/atomic.h
@@ -1,6 +1,13 @@
 #ifndef _ASM_X86_ATOMIC_H
 #define _ASM_X86_ATOMIC_H
 
+#ifdef __FRAMAC__
+/* Use C definitions for Frama-C */
+#include <asm-generic/atomic.h>
+#include <asm-generic/atomic64.h>
+
+#else /* __FRAMAC__ */
+
 #include <linux/compiler.h>
 #include <linux/types.h>
 #include <asm/processor.h>
@@ -250,4 +257,6 @@ static inline void atomic_or_long(unsign
 # include <asm/atomic64_64.h>
 #endif
 
+#endif /* __FRAMAC__ */
+
 #endif /* _ASM_X86_ATOMIC_H */
--- a/arch/x86/um/Kconfig
+++ b/arch/x86/um/Kconfig
@@ -12,6 +12,7 @@ endmenu
 
 config UML_X86
 	def_bool y
+	select GENERIC_ATOMIC64
 	select GENERIC_FIND_FIRST_BIT
 
 config 64BIT
--- a/arch/x86/include/uapi/asm/swab.h
+++ b/arch/x86/include/uapi/asm/swab.h
@@ -1,6 +1,10 @@
 #ifndef _ASM_X86_SWAB_H
 #define _ASM_X86_SWAB_H
 
+#ifdef __FRAMAC__
+/* Use C definitions from include/uapi/linux/swab.h for Frama-C */
+#else /* __FRAMAC__ */
+
 #include <linux/types.h>
 #include <linux/compiler.h>
 
@@ -33,4 +37,5 @@ static inline __attribute_const__ __u64
 }
 #define __arch_swab64 __arch_swab64
 
+#endif /* __FRAMAC__ */
 #endif /* _ASM_X86_SWAB_H */
--- a/include/linux/math64.h
+++ b/include/linux/math64.h
@@ -120,9 +120,11 @@ __iter_div_u64_rem(u64 dividend, u32 div
 	u32 ret = 0;
 
 	while (dividend >= divisor) {
+#ifndef __FRAMAC__
 		/* The following asm() prevents the compiler from
 		   optimising this loop into a modulo operation.  */
 		asm("" : "+rm"(dividend));
+#endif
 
 		dividend -= divisor;
 		ret++;
--- a/arch/um/include/asm/thread_info.h
+++ b/arch/um/include/asm/thread_info.h
@@ -47,6 +47,11 @@ struct thread_info {
 /* how to get the thread information struct from C */
 static inline struct thread_info *current_thread_info(void)
 {
+#ifdef __FRAMAC__
+	/* Get stack pointer from local variable, without asm */
+	unsigned long mask = THREAD_SIZE - 1;
+	return (struct thread_info *)(((unsigned long)&mask) & ~mask);
+#else /* __FRAMAC__ */
 	struct thread_info *ti;
 	unsigned long mask = THREAD_SIZE - 1;
 	void *p;
@@ -54,6 +59,7 @@ static inline struct thread_info *curren
 	asm volatile ("" : "=r" (p) : "0" (&ti));
 	ti = (struct thread_info *) (((unsigned long)p) & ~mask);
 	return ti;
+#endif /* __FRAMAC__ */
 }
 
 #define THREAD_SIZE_ORDER CONFIG_KERNEL_STACK_ORDER
--- a/arch/x86/include/asm/local.h
+++ b/arch/x86/include/asm/local.h
@@ -1,4 +1,10 @@
 #ifndef _ASM_X86_LOCAL_H
+#ifdef __FRAMAC__
+/* Use C definitions for Frama-C */
+#include <asm-generic/local.h>
+
+#else /* __FRAMAC__ */
+
 #define _ASM_X86_LOCAL_H
 
 #include <linux/percpu.h>
@@ -158,4 +164,5 @@ static inline long local_sub_return(long
 #define __local_add(i, l)	local_add((i), (l))
 #define __local_sub(i, l)	local_sub((i), (l))
 
+#endif /* __FRAMAC__ */
 #endif /* _ASM_X86_LOCAL_H */
--- a/arch/x86/um/asm/processor.h
+++ b/arch/x86/um/asm/processor.h
@@ -19,11 +19,16 @@
 
 #include <asm/user.h>
 
+#ifdef __FRAMAC__
+/* Avoid ASM in Frama-C */
+#define rep_nop() do {} while (0)
+#else /* __FRAMAC__ */
 /* REP NOP (PAUSE) is a good thing to insert into busy-wait loops. */
 static inline void rep_nop(void)
 {
 	__asm__ __volatile__("rep;nop": : :"memory");
 }
+#endif /* __FRAMAC__ */
 
 #define cpu_relax()		rep_nop()
 #define cpu_relax_lowlatency()	cpu_relax()
--- a/arch/x86/include/asm/cmpxchg_32.h
+++ b/arch/x86/include/asm/cmpxchg_32.h
@@ -1,6 +1,12 @@
 #ifndef _ASM_X86_CMPXCHG_32_H
 #define _ASM_X86_CMPXCHG_32_H
 
+#ifdef __FRAMAC__
+/* Use C definitions for Frama-C */
+#include <asm-generic/cmpxchg.h>
+
+#else /* __FRAMAC__ */
+
 /*
  * Note: if you use set64_bit(), __cmpxchg64(), or their variants, you
  *       you need to test for the feature in boot_cpu_data.
@@ -111,4 +117,5 @@ static inline u64 __cmpxchg64_local(vola
 
 #define system_has_cmpxchg_double() cpu_has_cx8
 
+#endif /* __FRAMAC__ */
 #endif /* _ASM_X86_CMPXCHG_32_H */
--- a/arch/x86/include/asm/cmpxchg.h
+++ b/arch/x86/include/asm/cmpxchg.h
@@ -4,6 +4,12 @@
 #include <linux/compiler.h>
 #include <asm/alternative.h> /* Provides LOCK_PREFIX */
 
+#ifdef __FRAMAC__
+/* Use C definitions for Frama-C */
+#include <asm-generic/cmpxchg.h>
+
+#else /* __FRAMAC__ */
+
 #define __HAVE_ARCH_CMPXCHG 1
 
 /*
@@ -230,4 +236,5 @@ extern void __add_wrong_size(void)
 #define cmpxchg_double_local(p1, p2, o1, o2, n1, n2) \
 	__cmpxchg_double(, p1, p2, o1, o2, n1, n2)
 
+#endif /* __FRAMAC__ */
 #endif	/* ASM_X86_CMPXCHG_H */
--- a/kernel/time/time.c
+++ b/kernel/time/time.c
@@ -359,17 +359,21 @@ EXPORT_SYMBOL(mktime);
 void set_normalized_timespec(struct timespec *ts, time_t sec, s64 nsec)
 {
 	while (nsec >= NSEC_PER_SEC) {
+#ifndef __FRAMAC__
 		/*
 		 * The following asm() prevents the compiler from
 		 * optimising this loop into a modulo operation. See
 		 * also __iter_div_u64_rem() in include/linux/time.h
 		 */
 		asm("" : "+rm"(nsec));
+#endif
 		nsec -= NSEC_PER_SEC;
 		++sec;
 	}
 	while (nsec < 0) {
+#ifndef __FRAMAC__
 		asm("" : "+rm"(nsec));
+#endif
 		nsec += NSEC_PER_SEC;
 		--sec;
 	}
@@ -439,17 +443,21 @@ EXPORT_SYMBOL(ns_to_timeval);
 void set_normalized_timespec64(struct timespec64 *ts, time64_t sec, s64 nsec)
 {
 	while (nsec >= NSEC_PER_SEC) {
+#ifndef __FRAMAC__
 		/*
 		 * The following asm() prevents the compiler from
 		 * optimising this loop into a modulo operation. See
 		 * also __iter_div_u64_rem() in include/linux/time.h
 		 */
 		asm("" : "+rm"(nsec));
+#endif
 		nsec -= NSEC_PER_SEC;
 		++sec;
 	}
 	while (nsec < 0) {
+#ifndef __FRAMAC__
 		asm("" : "+rm"(nsec));
+#endif
 		nsec += NSEC_PER_SEC;
 		--sec;
 	}
--- a/arch/x86/include/asm/div64.h
+++ b/arch/x86/include/asm/div64.h
@@ -1,7 +1,8 @@
 #ifndef _ASM_X86_DIV64_H
 #define _ASM_X86_DIV64_H
 
-#ifdef CONFIG_X86_32
+/* Don't use asm with Frama-C */
+#if defined(CONFIG_X86_32) && !defined(__FRAMAC__)
 
 #include <linux/types.h>
 #include <linux/log2.h>
--- a/arch/x86/include/asm/signal.h
+++ b/arch/x86/include/asm/signal.h
@@ -36,7 +36,8 @@ extern void do_notify_resume(struct pt_r
 
 #include <asm/sigcontext.h>
 
-#ifdef __i386__
+/* Don't use asm with Frama-C */
+#if defined(__i386__) && !defined(__FRAMAC__)
 
 #define __HAVE_ARCH_SIG_BITOPS
 
--- a/arch/x86/um/asm/checksum.h
+++ b/arch/x86/um/asm/checksum.h
@@ -4,6 +4,12 @@
 #include <linux/string.h>
 #include <linux/in6.h>
 
+#ifdef __FRAMAC__
+/* Use C definitions for Frama-C */
+#include <asm-generic/checksum.h>
+
+#else /* __FRAMAC__ */
+
 /*
  * computes the checksum of a memory block at buff, length len,
  * and adds in "sum" (32-bit)
@@ -151,4 +157,5 @@ static inline __sum16 ip_fast_csum(const
 # include "checksum_64.h"
 #endif
 
+#endif /* __FRAMAC__ */
 #endif
--- a/arch/x86/um/asm/processor_32.h
+++ b/arch/x86/um/asm/processor_32.h
@@ -52,10 +52,19 @@ static inline void arch_copy_thread(stru
  * instruction pointer ("program counter"). Stolen
  * from asm-i386/processor.h
  */
+#ifdef __FRAMAC__
+/* Avoid ASM in Frama-C */
+static inline void *current_text_addr(void) {
+	return __builtin_return_address(0);
+}
+#define current_sp() FRAMAC_REG_SP
+#define current_bp() FRAMAC_REG_BP
+#else /* __FRAMAC__ */
 #define current_text_addr() \
 	({ void *pc; __asm__("movl $1f,%0\n1:":"=g" (pc)); pc; })
 
 #define current_sp() ({ void *sp; __asm__("movl %%esp, %0" : "=r" (sp) : ); sp; })
 #define current_bp() ({ unsigned long bp; __asm__("movl %%ebp, %0" : "=r" (bp) : ); bp; })
+#endif /* __FRAMAC__ */
 
 #endif
--- a/arch/x86/include/asm/special_insns.h
+++ b/arch/x86/include/asm/special_insns.h
@@ -4,6 +4,10 @@
 
 #ifdef __KERNEL__
 
+#ifdef __FRAMAC__
+/* Avoid ASM in Frama-C */
+#else /* __FRAMAC__ */
+
 static inline void native_clts(void)
 {
 	asm volatile("clts");
@@ -202,6 +206,7 @@ static inline void clflushopt(volatile v
 #define nop() asm volatile ("nop")
 
 
+#endif /* __FRAMAC__ */
 #endif /* __KERNEL__ */
 
 #endif /* _ASM_X86_SPECIAL_INSNS_H */
--- a/arch/x86/um/delay.c
+++ b/arch/x86/um/delay.c
@@ -12,6 +12,24 @@
 #include <linux/delay.h>
 #include <asm/param.h>
 
+#ifdef __FRAMAC__
+/* Avoid ASM in Frama-C */
+void __delay(unsigned long loops)
+{
+	while (--loops)
+		;
+}
+EXPORT_SYMBOL(__delay);
+
+inline void __const_udelay(unsigned long xloops)
+{
+	while (--xloops)
+		;
+}
+EXPORT_SYMBOL(__const_udelay);
+
+#else /* __FRAMAC__ */
+
 void __delay(unsigned long loops)
 {
 	asm volatile(
@@ -47,6 +65,8 @@ inline void __const_udelay(unsigned long
 }
 EXPORT_SYMBOL(__const_udelay);
 
+#endif /* __FRAMAC__ */
+
 void __udelay(unsigned long usecs)
 {
 	__const_udelay(usecs * 0x000010c7); /* 2**32 / 1000000 (rounded up) */
